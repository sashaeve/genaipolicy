---
layout: default
title: Принципи використання ШІ
last_modified: 2024-09-23
version: 1.0-draft
license: Creative Commons Attribution 4.0 International License (CC BY 4.0)
---

# Принципи використання генеративного ШІ

Останні успіхи у сфері генеративного ШІ дають можливість виконувати велику кількість завдань швидше, якісніше та дешевше, що є беззаперечним фактом. Заборона генеративного ШІ за своєю суттю рівносильна забороні свого часу калькуляторів чи комп’ютерів, а, отже, повинна трактуватись як недалекоглядна і шкідлива ініціатива.

Ризики використання генеративного ШІ, як-от “галюцинування” є феноменом, який притаманний саме генеративному ШІ. По суті, на чинному етапі розвитку генеративного ШІ найважливішою навичкою при роботі є вміння розпізнати, зменшити, або прибрати ефект “галюцинування”. На цьому має фокусуватись навчальні матеріали, тренінги та нормативні документи.

Політика використання генеративного ШІ, як і будь-яка інша політика, повинна чітко відповідати на запитання, що вважається і що не вважається порушенням академічної доброчесності, авторських прав тощо, а також описувати алгоритм дії у випадку виявлення несвідомих порушень чи побічних ефектів.

Генеративний ШІ є універсальним інструментом, тому немає сенсу створювати вичерпний список завдань, де генеративний ШІ може чи не може використовуватись. Натомість важливо описати правила саме у вигляді політик. 

Регуляції на рівні конкретних організацій, урядів, об’єднань, спілок все ще знаходиться на ранньому етапі розвитку, тому нормальною може бути ситуація, коли ті чи інші правила будуть суперечити одне одному.

Розвиток генеративного ШІ є стрімким, завдяки чому деякі терміни можуть швидко втрачати свій сенс. Заокрема, “великі мовні моделі” коректно називати “великі мультимодальні моделі”, оскільки вони вміють працювати з різними типами інформації, як-от текст, зображення, відео, аудіо тощо. Цей факт потрібно враховувати при внесенні термінології до нормативних документів.

Політика використання генеративного штучного інтелекту:

1/ Використання технологій генеративного ШІ допускається **без маркування** для завдань, що стосуються процесу генерації ідей, проведення експериментів, пошуку інформації та потенційних рішень, машинного перекладу, зміни стилістики, дизайну, перевірки граматики, трансформації даних з одного формату в інший, та інших завдань, що не створюють нові знання, сенси, чи контент у фінальних творах. *Наприклад, машинний переклад за допомогою DeepL, Google Translate, Bing Translator, ChatGPT тощо або перевірка стилістики та граматики за допомогою Grammarly, ChatGPT тощо не вимагає маркування факту використання ШІ.*

2/ Використання технологій генеративного ШІ допускається **з маркуванням** у випадках, коли створений контент є завершеним твором або його невід’ємною частиною **без авторської адаптації**. *Якщо людина створила контент за допомогою ШІ та опублікувала її “як є”, то така дія вимагає маркування. Якщо ж людина створила контент, який був адаптований та стилістично оптимізований під авторський стиль, то таке використання не зобов’язує маркування і не вважатиметься порушенням принципів доброчесності.*

3/ Автор **зобов’язаний усунути характерні ознаки того чи іншого ШІ** у фінальному творі. Якщо такі ознаки ідентифіковані, то такий твір повинен вважатись невідповідним мінімальним стандартам незалежно від того, чи факт використання ШІ був вказаний чи ні. *Якщо автор не прибрав слова на кшталт “delve”, використав шаблонні відповіді чи залишив фрази, що чітко вказують на використання генеративного ШІ, то такий твір повинен вважатись таким, що порушує принципи доброчесності.*

4/ Для розв’язання завдань, що вимагають логічних чи математичних міркувань, а також у чуттєвих сферах, як-от медицина чи юриспруденція, перевагу потрібно надавати ШІ, що має засоби протидії ефекту «галюцинування» з обов’язковим зазначенням підходів, що використовувались для усунення ризиків. Для чуттєвих сфер обов’язково необхідно надати обгрунтування використання того чи іншого ШІ з точки зору визначених принципів етичного та відповідального використання.

5/ Для аналізу даних допускається використання ШІ за умови перевірки результатів у альтернативному інструменті та/або за допомогою програмних засобів з обов’язковим представленням програмних лінстингів або посиланням на публічні репозиторії (наприклад, у GitHub).
У випадку використання власних тренованих або тонко-налаштованих моделей необхідно зазначати детальну інформацію про набір даних, процес навчання та надати ключові метрики, що підтверджують її надійність.

6/ Допускається використання ШІ для роботи з персональними, чуттєвими та конфіденційними даними виключно у корпоративних версіях ШІ з обов’язковим зазначенням цього факту з дотриманням вимог до безпеки даних. Перевага надається роботі із знеособленими даними. Для процесу знеособлення даних рекомендується використання локальних ШІ.

7/ При використанні наборів даних для навчання моделей рекомендується проводити додатковий аналіз даних щодо наявності упереджень та включати результати цього аналізу у фінальний інтелектуальний продукт.

8/ Допускається використання інструментів ШІ для створення зображень, аудіо та відеоконтенту з маркуванням «Створено за допомогою ШІ» у випадку, якщо результат роботи ШІ використовується без змін. Зазначення конкретного інструменту, моделі, версії та іншої службової інформації є [рекомендованим](imagecaptions.md). У випадку, якщо ШІ використовується для покращення аудіо-графічної інформації, вказання факту використання ШІ є опційним. *Якщо зображення було створено за допомогою ШІ, то цей факт потрібно вказати. Якщо ж, приміром, якість старої фотографії була покращена за допомогою ШІ, то зазначати цей факт не є обов’язковим.*

9/ Усю інформацію про використання ШІ (інструмент, сервіс, модель та її версія тощо) потрібно описувати в окремому розділі **AI Acknowledgment / Використання ШІ**.

10/ Кожна організація повинна розробити **план дій для випадків виявлення неналежного маркування чи іншого порушення**, що пов’язаний з використанням ШІ.

--

# Generative AI Usage Policy

Recent advances in generative AI enable faster, higher-quality, and more cost-effective task completion across various domains. Prohibiting generative AI would be akin to banning calculators or computers, and should be considered a short-sighted and harmful initiative.

The risks associated with generative AI, such as "hallucinations," are inherent to this technology. At the current stage of generative AI development, the most crucial skill is the ability to identify, mitigate, or eliminate the hallucination effect. Training materials, workshops, and regulatory documents should focus on this aspect.

Any policy for using generative AI should clearly define what constitutes a violation of academic integrity, copyright, etc., and outline procedures for addressing unintentional violations or side effects.

Generative AI is a universal tool, so creating an exhaustive list of tasks where it can or cannot be used is impractical. Instead, it's important to describe rules in the form of policies.

Regulations at the level of specific organizations, governments, associations, and unions are still in early stages of development, so it's normal for certain rules to contradict each other.

The rapid development of generative AI means some terms may quickly lose relevance. For instance, "large language models" should now be referred to as "large multimodal models," as they can work with various types of information such as text, images, video, audio, etc. This fact should be considered when incorporating terminology into regulatory documents.

## Policy for Using Generative Artificial Intelligence:

1. The use of generative AI technologies is permitted without marking for tasks related to idea generation, conducting experiments, information search, potential solutions, machine translation, stylistic changes, design, grammar checking, data transformation from one format to another, and other tasks that do not create new knowledge, meanings, or content in final works. For example, machine translation using DeepL, Google Translate, Bing Translator, ChatGPT, etc., or checking style and grammar using Grammarly, ChatGPT, etc., does not require marking the use of AI.
2. The use of generative AI technologies is permitted with marking in cases where the created content is a completed work or its integral part without author adaptation. If a person created content using AI and published it "as is," such action requires marking. However, if a person created content that was adapted and stylistically optimized to the author's style, such use does not require marking and will not be considered a violation of integrity principles.
3. The author is obliged to remove characteristic signs of a particular AI in the final work. If such signs are identified, the work should be considered non-compliant with minimum standards, regardless of whether the use of AI was indicated or not. If the author did not remove words like "delve," used template responses, or left phrases that clearly indicate the use of generative AI, such work should be considered a violation of integrity principles.
4. For solving tasks that require logical or mathematical reasoning, as well as in sensitive areas such as medicine or jurisprudence, preference should be given to AI that has means to counteract the "hallucination" effect, with mandatory indication of the approaches used to eliminate risks. For sensitive areas, it is mandatory to provide justification for using a particular AI from the perspective of defined principles of ethical and responsible use.
5. For data analysis, the use of AI is permitted subject to verification of results in an alternative tool and/or using software tools with mandatory presentation of program listings or links to public repositories (e.g., on GitHub). In the case of using proprietary trained or fine-tuned models, it is necessary to provide detailed information about the dataset, training process, and key metrics that confirm its reliability.
6. The use of AI for working with personal, sensitive, and confidential data is permitted exclusively in corporate versions of AI, with mandatory indication of this fact and compliance with data security requirements. Preference is given to working with anonymized data. For the data anonymization process, the use of local AI is recommended.
7. When using datasets for training models, it is recommended to conduct additional data analysis for the presence of biases and include the results of this analysis in the final intellectual product.
8. The use of AI tools for creating images, audio, and video content is permitted with the marking "Created using AI" if the AI's output is used without changes. Specifying the specific tool, model, version, and other service information is recommended. If AI is used to improve audio-graphic information, indicating the fact of AI use is optional. If an image was created using AI, this fact must be indicated. However, if, for example, the quality of an old photograph was improved using AI, it is not mandatory to indicate this fact.
9. All information about the use of AI (tool, service, model and its version, etc.) should be described in a separate section titled "AI Acknowledgment."
10. Each organization should develop an action plan for cases of detecting improper marking or other violations related to the use of AI.

--

Останнє редагування: {{ page.last_modified }}  
Версія: {{ page.version }}  
Ліцензія: {{ page.license }}
